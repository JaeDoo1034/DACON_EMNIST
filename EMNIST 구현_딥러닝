{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "keras,tensorflow로 구현한 CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaeDoo1034/DACON_EMNIST/blob/master/EMNIST%20%EA%B5%AC%ED%98%84_%EB%94%A5%EB%9F%AC%EB%8B%9D\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeY-fkkoPzsn",
        "colab_type": "text"
      },
      "source": [
        "### Keras 와 Tensorflow로 구현한 CNN\n",
        "\n",
        "- CNN을 통해 글자에 가려진(노이즈가 있는) 숫자를 예측하기 위한 모델을 설계해 보았다.\\\n",
        "  (MNIST 데이터위에 필기체인 글씨가 겹쳐져 있는 데이터)\n",
        "\n",
        "- train.csv : 훈련 데이터 2048개\n",
        "- test.csv : 검증 데이터 20480개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPDoDkBdQAxB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "93c7f633-5309-48ac-806f-86dcd8384c1e"
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-rc1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 380.5MB 47kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 62.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 49.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVnDqQbCPzsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4a021bad-3faa-463a-83df-cbf32df60c5b"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "from matplotlib import font_manager, rc\n",
        "import platform\n",
        "\n",
        "\n",
        "try : \n",
        "    if platform.system() == 'Windows':\n",
        "    # 윈도우인 경우\n",
        "        font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
        "        rc('font', family=font_name)\n",
        "    else:    \n",
        "    # Mac 인 경우\n",
        "        rc('font', family='AppleGothic')\n",
        "except : \n",
        "    pass\n",
        "matplotlib.rcParams['axes.unicode_minus'] = False   "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWIsjRrWPzsw",
        "colab_type": "text"
      },
      "source": [
        "#### 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rToWmNLTRTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w6GkG9rRGQ8",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "83bc20be-04ae-43f9-dbd0-f5b7bdfbe72c"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0a8bcfc0-a7b7-4a5d-a60a-be8e0785c786\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0a8bcfc0-a7b7-4a5d-a60a-be8e0785c786\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test (1).csv\n",
            "Saving train.csv to train (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bJmDcoVgPzsx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "de81313f-333a-4053-b0cd-e93c3ebd99b3"
      },
      "source": [
        "train = pd.read_csv(io.BytesIO(uploaded['train.csv']))\n",
        "train.head()"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "      <th>letter</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 787 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  digit letter  0  1  2  3  4  ...  776  777  778  779  780  781  782  783\n",
              "0   1      5      L  1  1  1  4  3  ...    0    1    2    4    4    4    3    4\n",
              "1   2      0      B  0  4  0  0  4  ...    0    1    4    1    4    2    1    2\n",
              "2   3      4      L  1  1  2  2  1  ...    3    0    2    0    3    0    2    2\n",
              "3   4      9      D  1  2  0  2  0  ...    2    0    1    4    0    0    1    1\n",
              "4   5      6      A  3  0  2  4  0  ...    3    2    1    3    4    3    1    2\n",
              "\n",
              "[5 rows x 787 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPxbiYCrPzs3",
        "colab_type": "text"
      },
      "source": [
        "#### 데이터는 28*28의 2차원 이미지의 형태"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fczlRmM4nayc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "fe991117-b320-456a-c04e-fe8aac8579f3"
      },
      "source": [
        "train.digit.value_counts() /train.digit.value_counts().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    0.113770\n",
              "5    0.109863\n",
              "6    0.103516\n",
              "4    0.101074\n",
              "3    0.100098\n",
              "1    0.098633\n",
              "9    0.096191\n",
              "7    0.094727\n",
              "0    0.093262\n",
              "8    0.088867\n",
              "Name: digit, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aeIzi7sAPzs4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a831123a-6c52-4541-b24f-2c05631bc7bb"
      },
      "source": [
        "#28*28 의 형태\n",
        "train.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2048, 787)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI_dnmeePzs9",
        "colab_type": "text"
      },
      "source": [
        "target의 category / 가리고 있는 글자의 category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VVMWA4j9Pzs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "55fc411e-d528-4a4b-d642-833b1c904484"
      },
      "source": [
        "#고유값들 뽑아내기\n",
        "label1=train['letter'].unique()\n",
        "label2=train['digit'].unique()\n",
        "print(\"letter:\",np.sort(label1))\n",
        "print(\"digit:\",np.sort(label2))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "letter: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
            " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n",
            "digit: [0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQVPV-3yPztC",
        "colab_type": "text"
      },
      "source": [
        "#### CNN 모델에 이미지를 넣기 위해서는 3차원의 형태로 변환을 해 주어야 한다.\n",
        "- 여기서 초기 이미지는 28*28의 형태이므로\\\n",
        "  (데이터 수, 28, 28)의 형태로 변환한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhW_-xWbPztD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af8e7017-59f3-4e46-f4a2-826f0a94734d"
      },
      "source": [
        "#이미지데이터를 28*28의 형태로 변환\n",
        "image=np.array(train.iloc[:,3:]).reshape(-1,28,28)\n",
        "image.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2048, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "bi118ccBPztI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "outputId": "e0e2a6cc-1e5f-4a0b-91bc-a86976229ba6"
      },
      "source": [
        "image"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 1, 1, ..., 2, 0, 4],\n",
              "        [0, 1, 3, ..., 4, 1, 3],\n",
              "        [2, 0, 4, ..., 3, 3, 3],\n",
              "        ...,\n",
              "        [2, 1, 2, ..., 4, 1, 0],\n",
              "        [3, 3, 3, ..., 3, 3, 0],\n",
              "        [3, 2, 2, ..., 4, 3, 4]],\n",
              "\n",
              "       [[0, 4, 0, ..., 1, 4, 2],\n",
              "        [3, 3, 4, ..., 3, 4, 2],\n",
              "        [1, 4, 2, ..., 4, 0, 4],\n",
              "        ...,\n",
              "        [2, 4, 4, ..., 0, 0, 1],\n",
              "        [3, 1, 4, ..., 2, 2, 4],\n",
              "        [2, 1, 1, ..., 2, 1, 2]],\n",
              "\n",
              "       [[1, 1, 2, ..., 2, 4, 1],\n",
              "        [1, 2, 0, ..., 2, 4, 0],\n",
              "        [4, 2, 0, ..., 1, 3, 3],\n",
              "        ...,\n",
              "        [3, 0, 1, ..., 2, 2, 1],\n",
              "        [0, 3, 2, ..., 4, 2, 3],\n",
              "        [4, 4, 4, ..., 0, 2, 2]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[4, 0, 4, ..., 3, 2, 3],\n",
              "        [4, 3, 1, ..., 4, 4, 4],\n",
              "        [3, 2, 0, ..., 1, 3, 0],\n",
              "        ...,\n",
              "        [4, 0, 4, ..., 0, 2, 0],\n",
              "        [4, 3, 1, ..., 0, 4, 4],\n",
              "        [1, 3, 3, ..., 2, 0, 0]],\n",
              "\n",
              "       [[2, 3, 3, ..., 0, 1, 2],\n",
              "        [4, 1, 4, ..., 4, 0, 0],\n",
              "        [3, 1, 3, ..., 3, 3, 3],\n",
              "        ...,\n",
              "        [1, 1, 4, ..., 1, 0, 0],\n",
              "        [4, 4, 0, ..., 0, 1, 0],\n",
              "        [1, 0, 1, ..., 4, 3, 1]],\n",
              "\n",
              "       [[4, 2, 2, ..., 3, 1, 2],\n",
              "        [0, 2, 4, ..., 0, 3, 3],\n",
              "        [4, 1, 4, ..., 4, 4, 4],\n",
              "        ...,\n",
              "        [0, 0, 2, ..., 3, 2, 2],\n",
              "        [2, 3, 2, ..., 0, 1, 0],\n",
              "        [0, 3, 3, ..., 4, 3, 4]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "602oZ03wPztN",
        "colab_type": "text"
      },
      "source": [
        "### 현재 데이터가 어떤 이미지를 구성하고 있는지 알아본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErIV4-iZPztO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d164ba7f-6aec-4688-cdd3-695e119649a0"
      },
      "source": [
        "#몇개의 이미지가 어떤 형태인지 살펴 본다. random 하게 \n",
        "import random\n",
        "\n",
        "for i in range(10):\n",
        "    ran=random.randint(0,2048)\n",
        "    image=np.array(train.iloc[[ran],3:]).reshape(28,28).astype(np.float)\n",
        "    plt.imshow(image,cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"id:\",ran+1)\n",
        "    print(\"letter:\",train.iloc[ran]['letter'])\n",
        "    print(\"digit:\",train.iloc[ran]['digit'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['AppleGothic'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "id: 1624\n",
            "letter: C\n",
            "digit: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "id: 871\n",
            "letter: K\n",
            "digit: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "id: 578\n",
            "letter: V\n",
            "digit: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "id: 481\n",
            "letter: O\n",
            "digit: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "id: 1859\n",
            "letter: T\n",
            "digit: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "id: 1845\n",
            "letter: J\n",
            "digit: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "id: 1255\n",
            "letter: Z\n",
            "digit: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "id: 1220\n",
            "letter: P\n",
            "digit: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "id: 1711\n",
            "letter: X\n",
            "digit: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "id: 175\n",
            "letter: I\n",
            "digit: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIZguYUI0ZPW",
        "colab_type": "text"
      },
      "source": [
        "EDA & Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fltr_w80YV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " train= train.drop('id',axis = 1)"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjdzZSU20m9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = train.digit.values\n",
        "image_data = train.iloc[:,2:].values\n",
        "letter_data = train.letter.values"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmqI-KHd1SPw",
        "colab_type": "text"
      },
      "source": [
        "학습 데이터 : Cross-validation이용 X<br>\n",
        "& 데이터 종류 : 전체 데이터 1개, Threshold 1개, 문자를 숫자 비율로 대체 1개, 레이블 인코딩 1개, 3데이터 만 증식 1개, 8데이터 증식만 1개"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ9BYXqG1sdD",
        "colab_type": "text"
      },
      "source": [
        "**데이터 전처리**<br>\n",
        "1. 전체 데이터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frFc0MHQMwwQ",
        "colab_type": "text"
      },
      "source": [
        "2. Threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrYGhTHJMzIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Threshold_data= train.iloc[:,3:]"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6tTaYOUNA9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "696e21b6-8d32-472e-f15d-710f23bfb5eb"
      },
      "source": [
        "Threshold_data.head()"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>18</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 783 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  782  783\n",
              "0  1  1  4  3  0  0  4  4  3  ...    1    0    1    2    4    4    4    3    4\n",
              "1  4  0  0  4  1  1  1  4  2  ...    3    0    1    4    1    4    2    1    2\n",
              "2  1  2  2  1  1  1  0  2  1  ...    3    3    0    2    0    3    0    2    2\n",
              "3  2  0  2  0  4  0  3  4  3  ...    3    2    0    1    4    0    0    1    1\n",
              "4  0  2  4  0  3  0  4  2  4  ...    4    3    2    1    3    4    3    1    2\n",
              "\n",
              "[5 rows x 783 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgeGquwkNBEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_data_threshold = np.where(image_data < 50,0,image_data)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUYm34m6N1uP",
        "colab_type": "text"
      },
      "source": [
        "3. 문자 -> 숫자\n",
        " - 이거 방식 실패함.. 어떻게 반영할 지 고민해야함.. 지금은 시간 없음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EvVsehPWAp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Sep = train[['digit','letter']]"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtgVAS-LWE3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Sep = dict(list(Sep.groupby('letter')))"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAMXhVmpS39O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table_list  = []\n",
        "letter_list = []\n",
        "for i in list(Sep.keys()):\n",
        "    Test = Sep[i]\n",
        "    table = Test.digit.value_counts() / Test.digit.value_counts().sum()\n",
        "    letter = Test.digit.apply(lambda x : table[x])\n",
        "    letter_list.append(letter)"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Majx0MqFV_YQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_data = pd.concat(letter_list,axis = 0)"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNcUfiaJV_NI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "letter_trans = Test_data.reset_index().sort_values(by = 'index').digit"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZOBwvvbWazS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_3 = train.copy()\n",
        "train_3.letter = letter_trans"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6SQqA8QWaUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_data_average = train_3.iloc[:,1:]"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouQ6XGoNWZzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1 = image_data_average.letter\n",
        "test2 = image_data_average.iloc[:,1:]"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnY9M_N-YJTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "a608e731-199a-4f9a-aefa-7dc4d4856d08"
      },
      "source": [
        "image_data_average.values.reshape(-1,28,28,1)"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-242-4c188b4d9558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_data_average\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1607680 into shape (28,28,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuKEj1ArZEpF",
        "colab_type": "text"
      },
      "source": [
        "4. 3만 증식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mShguNhGZHSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Temppp = train[train.digit == 3].index"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_XKwtfoZG3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "c3b6ad08-ca35-4c39-c4ed-e96143941cc5"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>digit</th>\n",
              "      <th>letter</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 786 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   digit letter  0  1  2  3  4  5  ...  776  777  778  779  780  781  782  783\n",
              "0      5      L  1  1  1  4  3  0  ...    0    1    2    4    4    4    3    4\n",
              "1      0      B  0  4  0  0  4  1  ...    0    1    4    1    4    2    1    2\n",
              "2      4      L  1  1  2  2  1  1  ...    3    0    2    0    3    0    2    2\n",
              "3      9      D  1  2  0  2  0  4  ...    2    0    1    4    0    0    1    1\n",
              "4      6      A  3  0  2  4  0  3  ...    3    2    1    3    4    3    1    2\n",
              "\n",
              "[5 rows x 786 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zAz2hKZZGV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvBWzNZs-7tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.ndimage.interpolation import shift"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB48sMH-BqjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_cnn(data,target):\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, kernel_size=3, activation='relu',padding='same',\n",
        "                          input_shape=data.shape[1:]))\n",
        "  model.add(layers.Conv2D(64, kernel_size=3,padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2,2)))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "\n",
        "  model.add(layers.Conv2D(64, kernel_size=3,padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(64, kernel_size=3,padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2,2)))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "\n",
        "  model.add(layers.Conv2D(128, kernel_size=3,padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(128, kernel_size=3,padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2,2)))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(target.shape[1], activation='softmax'))\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7X1Y-HkCmhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO4eC6JyC1Er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e1dd9315-977b-498a-a814-c6d1dac00bf9"
      },
      "source": [
        "early_stop = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50),\n",
        "            keras.callbacks.ModelCheckpoint(filepath='C:/workspace/DACON/EMNIST/CNN_models/best_model1.h5',monitor='val_accuracy',save_best_only=True)]\n",
        "early_stop"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.callbacks.EarlyStopping at 0x7fa020c9cb00>,\n",
              " <tensorflow.python.keras.callbacks.ModelCheckpoint at 0x7fa020c9c390>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1-Q3AeHGdcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca0827ec-af21-4278-df09-ef51d51dccbc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ9E1J9QCDpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50),\n",
        "            keras.callbacks.ModelCheckpoint(filepath='C:/workspace/DACON/EMNIST/model/best_model_1.h5',monitor='val_accuracy',save_best_only=True)]\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch=x_train.shape[0]//batch, # 전체 데이터 수 / 배치 사이즈\n",
        "    epochs=epoch,\n",
        "    validation_data=test_datagen.flow(x_val, y_val),\n",
        "   # class_weight = class_weight,\n",
        "    verbose=2,\n",
        "    callbacks=early_stop\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFTlzUYeJPt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYcEz-AHKHN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data,val_data,train_label, val_label = train_test_split(image_data,target,test_size = 0.2,random_state = 42)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRFh0sAoKJ7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3a88bb2-c0a3-4adc-c39b-ef76b4ab1fe9"
      },
      "source": [
        "val_data.shape"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(410, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAZqnKacegRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3BXNMk7rFi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampling_func(data, sample_pct):\n",
        "\n",
        "    np.random.seed(123)\n",
        "\n",
        "    N = len(data)\n",
        "\n",
        "    sample_n = int(len(data)*sample_pct) # integer\n",
        "\n",
        "    sample = data.take(np.random.permutation(N)[:sample_n])\n",
        "\n",
        "    return sample"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lrhSvKb0nak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_train_ver2(total_data,number,aug_number):\n",
        "  # index추출\n",
        "  total_index= np.array(total_data.index)\n",
        "  Temp1= total_data[total_data.digit == aug_number]\n",
        "  Temp_index = np.array(Temp1.index)\n",
        "  other_index = np.setdiff1d(total_index,Temp_index)\n",
        "  \n",
        "  # 집중\n",
        "  train_aug = total_data.loc[Temp_index]\n",
        "  train_not_aug = total_data.loc[other_index]\n",
        "  \n",
        "  val_data_aug = train_aug.sample(frac = 0.2)#\n",
        "\n",
        "  val_index_aug = np.array(val_data_aug.index)\n",
        "  total_index = train_aug.index\n",
        "  train_index_aug  = np.setdiff1d(total_index,val_index_aug)\n",
        "\n",
        "  train_data_aug= train_aug.loc[train_index_aug]\n",
        "  train_data_aug\n",
        "  val_data_not = train_not_aug.sample(frac  = 0.2)#\n",
        "  val_not_index = np.array(val_data_not.index)\n",
        "  total_not_index = np.array(train_not_aug.index)\n",
        "  train_not_index = np.setdiff1d(total_not_index,val_not_index)\n",
        "  train_data_not = train_not_aug.loc[train_not_index]\n",
        "  \n",
        "  # train_test 분리 - 전부 데이터 프레임 형태=> numpy변환\n",
        "  aug_train_label = train_data_aug.digit.values\n",
        "  aug_train_data = train_data_aug.iloc[:,2:].values # 이것만 증식\n",
        "\n",
        "  not_aug_train_label = train_data_not.digit.values\n",
        "  not_aug_train_data = train_data_not.iloc[:,2:].values\n",
        "  \n",
        "  # 이미지 generator 3만\n",
        "  X_train_augmented = [image for image in aug_train_data]\n",
        "  y_train_augmented_two = [label for label in aug_train_label]\n",
        "  \n",
        "  \n",
        "  for dx,dy in ((1,0),(-1,0),(0,1),(0,-1)):\n",
        "    for image, label in zip(aug_train_data,aug_train_label):\n",
        "      X_train_augmented.append(shift_image(image,dx,dy))\n",
        "      y_train_augmented_two.append(label)\n",
        "      \n",
        "  \n",
        "    # numpy로 변환\n",
        "  X_train_augmented = np.array(X_train_augmented)\n",
        "  y_train_augmented_two = np.array(y_train_augmented_two)\n",
        "  \n",
        "  # val_data추출\n",
        "  val_1 = val_data_aug.iloc[:,2:]\n",
        "  val_2 = val_data_not.iloc[:,2:]\n",
        "  val_1_label = val_data_aug.digit\n",
        "  val_2_label = val_data_not.digit\n",
        "\n",
        "  # 데이터 합치기\n",
        "  X_train = np.r_[X_train_augmented,not_aug_train_data]\n",
        "  X_train_label = np.r_[y_train_augmented_two,not_aug_train_label]\n",
        "  \n",
        "  x_val = np.r_[val_1,val_2]\n",
        "  x_val_label = np.r_[val_1_label,val_2_label] \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  early_stop = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20),\n",
        "                keras.callbacks.ModelCheckpoint(filepath='/content/gdrive/My Drive/best_model_{}.h5'.format(number),monitor='val_accuracy',save_best_only=True)]\n",
        "\n",
        "  X_train =  X_train.reshape(-1,28,28,1).astype(np.float64)\n",
        "  y_train = to_categorical(X_train_label)\n",
        "  val_data1 = x_val.reshape(-1,28,28,1).astype(np.float64)\n",
        "  val_label1 = to_categorical(x_val_label)\n",
        "\n",
        "  model = model_cnn(X_train,y_train)\n",
        "  model.summary()\n",
        "  print(X_train.shape)\n",
        "  print(y_train.shape)\n",
        "  history_list = []\n",
        "  history = model.fit(\n",
        "  X_train,\n",
        "  y_train,\n",
        "  batch_size = 128, # 전체 데이터 수 / 배치 사이즈\n",
        "  epochs=300,\n",
        "  validation_data=(val_data1, val_label1),\n",
        "  verbose=2,\n",
        "  callbacks=early_stop)\n",
        "  history_list.append(history)\n",
        "  return history_list"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erpcsvZUXEHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_train(data,target,number):\n",
        "  #split = KFold(n_splits= 5, shuffle= True,random_state = 42)\n",
        "  #for train_index, val_index in split.split(data):\n",
        "   # train_data = data[train_index]\n",
        "    #val_data = data[val_index]\n",
        "    #train_label = target[train_index]\n",
        "    #val_label = target[val_index]\n",
        "  \n",
        "  # train_test_split\n",
        "  train_data1, val_data1 ,train_label1, val_label1 = train_test_split(data,target,test_size = 0.2,random_state = 42)\n",
        "\n",
        "  # 이미지 generator\n",
        "  X_train_augmented = [image for image in train_data1]\n",
        "  y_train_augmented_two = [label for label in train_label1]\n",
        "\n",
        "  for dx,dy in ((1,0),(-1,0),(0,1),(0,-1)):\n",
        "    for image, label in zip(train_data1,train_label1):\n",
        "      X_train_augmented.append(shift_image(image,dx,dy))\n",
        "      y_train_augmented_two.append(label)\n",
        "    # numpy로 변환\n",
        "  X_train_augmented = np.array(X_train_augmented)\n",
        "  y_train_augmented_two = np.array(y_train_augmented_two)\n",
        "\n",
        "  print(X_train_augmented.shape)\n",
        "  print(val_data1.shape)\n",
        "  early_stop = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20),\n",
        "                keras.callbacks.ModelCheckpoint(filepath='/content/gdrive/My Drive/best_model_{}.h5'.format(number),monitor='val_accuracy',save_best_only=True)]\n",
        "\n",
        "  X_train_augmented =  X_train_augmented.reshape(-1,28,28,1).astype(np.float64)\n",
        "  y_train_augmented_two = to_categorical(y_train_augmented_two)\n",
        "  val_data1 = val_data1.reshape(-1,28,28,1).astype(np.float64)\n",
        "  val_label1 = to_categorical(val_label1)\n",
        "\n",
        "  model = model_cnn(X_train_augmented,y_train_augmented_two)\n",
        "  model.summary()\n",
        "  history_list = []\n",
        "  history = model.fit(\n",
        "  X_train_augmented,\n",
        "  y_train_augmented_two,\n",
        "  batch_size = 128, # 전체 데이터 수 / 배치 사이즈\n",
        "  epochs=300,\n",
        "  validation_data=(val_data1, val_label1),\n",
        "  verbose=2,\n",
        "  callbacks=early_stop)\n",
        "  history_list.append(history)\n",
        "  return history_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn_4AyPt0nlZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f071f97b-df39-45c6-a648-ee06742d9bd8"
      },
      "source": [
        "model_train(image_data,target,1)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8190, 784)\n",
            "(410, 784)\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_72 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 489,354\n",
            "Trainable params: 489,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8190 samples, validate on 410 samples\n",
            "Epoch 1/300\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f9fbc1aa510> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f9fbc1aa510> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "8190/8190 - 2s - loss: 2.5234 - accuracy: 0.1192 - val_loss: 2.2839 - val_accuracy: 0.1585\n",
            "Epoch 2/300\n",
            "8190/8190 - 1s - loss: 2.2116 - accuracy: 0.1728 - val_loss: 1.9615 - val_accuracy: 0.3293\n",
            "Epoch 3/300\n",
            "8190/8190 - 1s - loss: 1.8284 - accuracy: 0.3573 - val_loss: 1.5903 - val_accuracy: 0.4805\n",
            "Epoch 4/300\n",
            "8190/8190 - 1s - loss: 1.4876 - accuracy: 0.4911 - val_loss: 1.3446 - val_accuracy: 0.5756\n",
            "Epoch 5/300\n",
            "8190/8190 - 1s - loss: 1.2312 - accuracy: 0.5860 - val_loss: 1.0236 - val_accuracy: 0.6610\n",
            "Epoch 6/300\n",
            "8190/8190 - 1s - loss: 0.9570 - accuracy: 0.6761 - val_loss: 0.8677 - val_accuracy: 0.7098\n",
            "Epoch 7/300\n",
            "8190/8190 - 1s - loss: 0.7940 - accuracy: 0.7225 - val_loss: 0.7151 - val_accuracy: 0.7585\n",
            "Epoch 8/300\n",
            "8190/8190 - 1s - loss: 0.6621 - accuracy: 0.7792 - val_loss: 0.6975 - val_accuracy: 0.7732\n",
            "Epoch 9/300\n",
            "8190/8190 - 1s - loss: 0.5856 - accuracy: 0.7991 - val_loss: 0.6080 - val_accuracy: 0.7927\n",
            "Epoch 10/300\n",
            "8190/8190 - 1s - loss: 0.5149 - accuracy: 0.8223 - val_loss: 0.5893 - val_accuracy: 0.8024\n",
            "Epoch 11/300\n",
            "8190/8190 - 1s - loss: 0.4348 - accuracy: 0.8479 - val_loss: 0.5482 - val_accuracy: 0.8195\n",
            "Epoch 12/300\n",
            "8190/8190 - 1s - loss: 0.3896 - accuracy: 0.8626 - val_loss: 0.5523 - val_accuracy: 0.8317\n",
            "Epoch 13/300\n",
            "8190/8190 - 1s - loss: 0.3343 - accuracy: 0.8822 - val_loss: 0.5628 - val_accuracy: 0.8098\n",
            "Epoch 14/300\n",
            "8190/8190 - 1s - loss: 0.3121 - accuracy: 0.8918 - val_loss: 0.5486 - val_accuracy: 0.8244\n",
            "Epoch 15/300\n",
            "8190/8190 - 1s - loss: 0.2718 - accuracy: 0.9037 - val_loss: 0.5631 - val_accuracy: 0.8220\n",
            "Epoch 16/300\n",
            "8190/8190 - 1s - loss: 0.2636 - accuracy: 0.9098 - val_loss: 0.5053 - val_accuracy: 0.8317\n",
            "Epoch 17/300\n",
            "8190/8190 - 1s - loss: 0.2299 - accuracy: 0.9175 - val_loss: 0.5353 - val_accuracy: 0.8244\n",
            "Epoch 18/300\n",
            "8190/8190 - 1s - loss: 0.2075 - accuracy: 0.9277 - val_loss: 0.5180 - val_accuracy: 0.8488\n",
            "Epoch 19/300\n",
            "8190/8190 - 1s - loss: 0.2032 - accuracy: 0.9272 - val_loss: 0.4891 - val_accuracy: 0.8390\n",
            "Epoch 20/300\n",
            "8190/8190 - 1s - loss: 0.1847 - accuracy: 0.9337 - val_loss: 0.5085 - val_accuracy: 0.8317\n",
            "Epoch 21/300\n",
            "8190/8190 - 1s - loss: 0.1781 - accuracy: 0.9407 - val_loss: 0.5347 - val_accuracy: 0.8293\n",
            "Epoch 22/300\n",
            "8190/8190 - 1s - loss: 0.1560 - accuracy: 0.9451 - val_loss: 0.5556 - val_accuracy: 0.8244\n",
            "Epoch 23/300\n",
            "8190/8190 - 1s - loss: 0.1482 - accuracy: 0.9507 - val_loss: 0.5825 - val_accuracy: 0.8146\n",
            "Epoch 24/300\n",
            "8190/8190 - 1s - loss: 0.1349 - accuracy: 0.9559 - val_loss: 0.6819 - val_accuracy: 0.8146\n",
            "Epoch 25/300\n",
            "8190/8190 - 1s - loss: 0.1455 - accuracy: 0.9513 - val_loss: 0.5435 - val_accuracy: 0.8341\n",
            "Epoch 26/300\n",
            "8190/8190 - 1s - loss: 0.1233 - accuracy: 0.9569 - val_loss: 0.5662 - val_accuracy: 0.8390\n",
            "Epoch 27/300\n",
            "8190/8190 - 1s - loss: 0.1371 - accuracy: 0.9569 - val_loss: 0.5480 - val_accuracy: 0.8244\n",
            "Epoch 28/300\n",
            "8190/8190 - 1s - loss: 0.1059 - accuracy: 0.9654 - val_loss: 0.5189 - val_accuracy: 0.8439\n",
            "Epoch 29/300\n",
            "8190/8190 - 1s - loss: 0.1073 - accuracy: 0.9614 - val_loss: 0.5644 - val_accuracy: 0.8341\n",
            "Epoch 30/300\n",
            "8190/8190 - 1s - loss: 0.1059 - accuracy: 0.9652 - val_loss: 0.5228 - val_accuracy: 0.8537\n",
            "Epoch 31/300\n",
            "8190/8190 - 1s - loss: 0.1006 - accuracy: 0.9654 - val_loss: 0.5918 - val_accuracy: 0.8585\n",
            "Epoch 32/300\n",
            "8190/8190 - 1s - loss: 0.0936 - accuracy: 0.9669 - val_loss: 0.5942 - val_accuracy: 0.8439\n",
            "Epoch 33/300\n",
            "8190/8190 - 1s - loss: 0.1008 - accuracy: 0.9691 - val_loss: 0.6186 - val_accuracy: 0.8390\n",
            "Epoch 34/300\n",
            "8190/8190 - 1s - loss: 0.0847 - accuracy: 0.9703 - val_loss: 0.6499 - val_accuracy: 0.8220\n",
            "Epoch 35/300\n",
            "8190/8190 - 1s - loss: 0.0900 - accuracy: 0.9680 - val_loss: 0.7267 - val_accuracy: 0.8122\n",
            "Epoch 36/300\n",
            "8190/8190 - 1s - loss: 0.0946 - accuracy: 0.9683 - val_loss: 0.5707 - val_accuracy: 0.8659\n",
            "Epoch 37/300\n",
            "8190/8190 - 1s - loss: 0.0849 - accuracy: 0.9712 - val_loss: 0.6103 - val_accuracy: 0.8512\n",
            "Epoch 38/300\n",
            "8190/8190 - 1s - loss: 0.0780 - accuracy: 0.9725 - val_loss: 0.5749 - val_accuracy: 0.8732\n",
            "Epoch 39/300\n",
            "8190/8190 - 1s - loss: 0.0634 - accuracy: 0.9781 - val_loss: 0.6407 - val_accuracy: 0.8585\n",
            "Epoch 40/300\n",
            "8190/8190 - 1s - loss: 0.0858 - accuracy: 0.9701 - val_loss: 0.7241 - val_accuracy: 0.8195\n",
            "Epoch 41/300\n",
            "8190/8190 - 1s - loss: 0.0696 - accuracy: 0.9758 - val_loss: 0.6488 - val_accuracy: 0.8317\n",
            "Epoch 42/300\n",
            "8190/8190 - 1s - loss: 0.0714 - accuracy: 0.9767 - val_loss: 0.6650 - val_accuracy: 0.8512\n",
            "Epoch 43/300\n",
            "8190/8190 - 1s - loss: 0.0601 - accuracy: 0.9772 - val_loss: 0.6015 - val_accuracy: 0.8732\n",
            "Epoch 44/300\n",
            "8190/8190 - 1s - loss: 0.0688 - accuracy: 0.9785 - val_loss: 0.5790 - val_accuracy: 0.8537\n",
            "Epoch 45/300\n",
            "8190/8190 - 1s - loss: 0.0551 - accuracy: 0.9818 - val_loss: 0.6072 - val_accuracy: 0.8585\n",
            "Epoch 46/300\n",
            "8190/8190 - 1s - loss: 0.0596 - accuracy: 0.9812 - val_loss: 0.6003 - val_accuracy: 0.8610\n",
            "Epoch 47/300\n",
            "8190/8190 - 1s - loss: 0.0674 - accuracy: 0.9772 - val_loss: 0.5663 - val_accuracy: 0.8488\n",
            "Epoch 48/300\n",
            "8190/8190 - 1s - loss: 0.0687 - accuracy: 0.9772 - val_loss: 0.6533 - val_accuracy: 0.8390\n",
            "Epoch 49/300\n",
            "8190/8190 - 1s - loss: 0.0755 - accuracy: 0.9745 - val_loss: 0.6712 - val_accuracy: 0.8220\n",
            "Epoch 50/300\n",
            "8190/8190 - 1s - loss: 0.0760 - accuracy: 0.9748 - val_loss: 0.5281 - val_accuracy: 0.8488\n",
            "Epoch 51/300\n",
            "8190/8190 - 1s - loss: 0.0573 - accuracy: 0.9813 - val_loss: 0.6582 - val_accuracy: 0.8390\n",
            "Epoch 52/300\n",
            "8190/8190 - 1s - loss: 0.0638 - accuracy: 0.9790 - val_loss: 0.6126 - val_accuracy: 0.8439\n",
            "Epoch 53/300\n",
            "8190/8190 - 1s - loss: 0.0552 - accuracy: 0.9802 - val_loss: 0.5696 - val_accuracy: 0.8537\n",
            "Epoch 54/300\n",
            "8190/8190 - 1s - loss: 0.0521 - accuracy: 0.9818 - val_loss: 0.6734 - val_accuracy: 0.8463\n",
            "Epoch 55/300\n",
            "8190/8190 - 1s - loss: 0.0768 - accuracy: 0.9750 - val_loss: 0.6119 - val_accuracy: 0.8317\n",
            "Epoch 56/300\n",
            "8190/8190 - 1s - loss: 0.0658 - accuracy: 0.9791 - val_loss: 0.6724 - val_accuracy: 0.8561\n",
            "Epoch 57/300\n",
            "8190/8190 - 1s - loss: 0.0700 - accuracy: 0.9772 - val_loss: 0.6333 - val_accuracy: 0.8537\n",
            "Epoch 58/300\n",
            "8190/8190 - 1s - loss: 0.0613 - accuracy: 0.9792 - val_loss: 0.6247 - val_accuracy: 0.8610\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.callbacks.History at 0x7f9f770d5a90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cP_GILD0nON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56229557-ffbf-46f2-b2a7-a7e119c6eb70"
      },
      "source": [
        "model_train(image_data_threshold,target,2)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8190, 784)\n",
            "(410, 784)\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_78 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 489,354\n",
            "Trainable params: 489,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8190 samples, validate on 410 samples\n",
            "Epoch 1/300\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f9fc0cd4ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f9fc0cd4ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "8190/8190 - 2s - loss: 2.6285 - accuracy: 0.1142 - val_loss: 2.3006 - val_accuracy: 0.0927\n",
            "Epoch 2/300\n",
            "8190/8190 - 1s - loss: 2.2643 - accuracy: 0.1424 - val_loss: 2.1769 - val_accuracy: 0.2390\n",
            "Epoch 3/300\n",
            "8190/8190 - 1s - loss: 2.1164 - accuracy: 0.2148 - val_loss: 1.9910 - val_accuracy: 0.3439\n",
            "Epoch 4/300\n",
            "8190/8190 - 1s - loss: 1.9184 - accuracy: 0.3039 - val_loss: 1.8901 - val_accuracy: 0.3805\n",
            "Epoch 5/300\n",
            "8190/8190 - 1s - loss: 1.6951 - accuracy: 0.4035 - val_loss: 1.6708 - val_accuracy: 0.4341\n",
            "Epoch 6/300\n",
            "8190/8190 - 1s - loss: 1.5086 - accuracy: 0.4795 - val_loss: 1.6813 - val_accuracy: 0.4293\n",
            "Epoch 7/300\n",
            "8190/8190 - 1s - loss: 1.2922 - accuracy: 0.5586 - val_loss: 1.2509 - val_accuracy: 0.6098\n",
            "Epoch 8/300\n",
            "8190/8190 - 1s - loss: 1.1211 - accuracy: 0.6225 - val_loss: 1.3149 - val_accuracy: 0.5488\n",
            "Epoch 9/300\n",
            "8190/8190 - 1s - loss: 0.9796 - accuracy: 0.6700 - val_loss: 1.3023 - val_accuracy: 0.5561\n",
            "Epoch 10/300\n",
            "8190/8190 - 1s - loss: 0.8810 - accuracy: 0.7000 - val_loss: 1.1245 - val_accuracy: 0.6415\n",
            "Epoch 11/300\n",
            "8190/8190 - 1s - loss: 0.7552 - accuracy: 0.7442 - val_loss: 0.9793 - val_accuracy: 0.6780\n",
            "Epoch 12/300\n",
            "8190/8190 - 1s - loss: 0.6912 - accuracy: 0.7614 - val_loss: 0.9704 - val_accuracy: 0.6732\n",
            "Epoch 13/300\n",
            "8190/8190 - 1s - loss: 0.5929 - accuracy: 0.7974 - val_loss: 0.8247 - val_accuracy: 0.7293\n",
            "Epoch 14/300\n",
            "8190/8190 - 1s - loss: 0.5415 - accuracy: 0.8106 - val_loss: 0.7347 - val_accuracy: 0.7683\n",
            "Epoch 15/300\n",
            "8190/8190 - 1s - loss: 0.4953 - accuracy: 0.8281 - val_loss: 0.8484 - val_accuracy: 0.7098\n",
            "Epoch 16/300\n",
            "8190/8190 - 1s - loss: 0.4508 - accuracy: 0.8413 - val_loss: 0.7494 - val_accuracy: 0.7512\n",
            "Epoch 17/300\n",
            "8190/8190 - 1s - loss: 0.4042 - accuracy: 0.8587 - val_loss: 0.7554 - val_accuracy: 0.7317\n",
            "Epoch 18/300\n",
            "8190/8190 - 1s - loss: 0.3935 - accuracy: 0.8595 - val_loss: 0.8324 - val_accuracy: 0.7073\n",
            "Epoch 19/300\n",
            "8190/8190 - 1s - loss: 0.3548 - accuracy: 0.8773 - val_loss: 0.7320 - val_accuracy: 0.7317\n",
            "Epoch 20/300\n",
            "8190/8190 - 1s - loss: 0.3091 - accuracy: 0.8906 - val_loss: 0.8738 - val_accuracy: 0.6951\n",
            "Epoch 21/300\n",
            "8190/8190 - 1s - loss: 0.2910 - accuracy: 0.8985 - val_loss: 1.1943 - val_accuracy: 0.6439\n",
            "Epoch 22/300\n",
            "8190/8190 - 1s - loss: 0.2887 - accuracy: 0.8991 - val_loss: 0.9136 - val_accuracy: 0.6927\n",
            "Epoch 23/300\n",
            "8190/8190 - 1s - loss: 0.2655 - accuracy: 0.9085 - val_loss: 0.7727 - val_accuracy: 0.7488\n",
            "Epoch 24/300\n",
            "8190/8190 - 1s - loss: 0.2440 - accuracy: 0.9175 - val_loss: 0.8228 - val_accuracy: 0.7317\n",
            "Epoch 25/300\n",
            "8190/8190 - 1s - loss: 0.2358 - accuracy: 0.9168 - val_loss: 0.9089 - val_accuracy: 0.7171\n",
            "Epoch 26/300\n",
            "8190/8190 - 1s - loss: 0.2256 - accuracy: 0.9248 - val_loss: 0.7536 - val_accuracy: 0.7561\n",
            "Epoch 27/300\n",
            "8190/8190 - 1s - loss: 0.1887 - accuracy: 0.9361 - val_loss: 1.0381 - val_accuracy: 0.6659\n",
            "Epoch 28/300\n",
            "8190/8190 - 1s - loss: 0.1880 - accuracy: 0.9357 - val_loss: 0.7593 - val_accuracy: 0.7537\n",
            "Epoch 29/300\n",
            "8190/8190 - 1s - loss: 0.1809 - accuracy: 0.9372 - val_loss: 0.7888 - val_accuracy: 0.7488\n",
            "Epoch 30/300\n",
            "8190/8190 - 1s - loss: 0.1671 - accuracy: 0.9415 - val_loss: 0.8294 - val_accuracy: 0.7439\n",
            "Epoch 31/300\n",
            "8190/8190 - 1s - loss: 0.1703 - accuracy: 0.9414 - val_loss: 0.9326 - val_accuracy: 0.7317\n",
            "Epoch 32/300\n",
            "8190/8190 - 1s - loss: 0.1721 - accuracy: 0.9436 - val_loss: 0.8301 - val_accuracy: 0.7610\n",
            "Epoch 33/300\n",
            "8190/8190 - 2s - loss: 0.1313 - accuracy: 0.9549 - val_loss: 0.7400 - val_accuracy: 0.7805\n",
            "Epoch 34/300\n",
            "8190/8190 - 1s - loss: 0.1533 - accuracy: 0.9487 - val_loss: 0.6895 - val_accuracy: 0.8098\n",
            "Epoch 35/300\n",
            "8190/8190 - 1s - loss: 0.1538 - accuracy: 0.9455 - val_loss: 0.7796 - val_accuracy: 0.7439\n",
            "Epoch 36/300\n",
            "8190/8190 - 1s - loss: 0.1266 - accuracy: 0.9560 - val_loss: 0.8185 - val_accuracy: 0.7634\n",
            "Epoch 37/300\n",
            "8190/8190 - 1s - loss: 0.1481 - accuracy: 0.9482 - val_loss: 0.8054 - val_accuracy: 0.7976\n",
            "Epoch 38/300\n",
            "8190/8190 - 1s - loss: 0.1322 - accuracy: 0.9548 - val_loss: 1.0102 - val_accuracy: 0.7341\n",
            "Epoch 39/300\n",
            "8190/8190 - 1s - loss: 0.1165 - accuracy: 0.9603 - val_loss: 0.9711 - val_accuracy: 0.7341\n",
            "Epoch 40/300\n",
            "8190/8190 - 1s - loss: 0.1264 - accuracy: 0.9571 - val_loss: 0.8724 - val_accuracy: 0.7463\n",
            "Epoch 41/300\n",
            "8190/8190 - 1s - loss: 0.1066 - accuracy: 0.9625 - val_loss: 0.9183 - val_accuracy: 0.7854\n",
            "Epoch 42/300\n",
            "8190/8190 - 1s - loss: 0.1233 - accuracy: 0.9571 - val_loss: 0.8476 - val_accuracy: 0.7756\n",
            "Epoch 43/300\n",
            "8190/8190 - 1s - loss: 0.1208 - accuracy: 0.9611 - val_loss: 0.8557 - val_accuracy: 0.7585\n",
            "Epoch 44/300\n",
            "8190/8190 - 1s - loss: 0.0988 - accuracy: 0.9632 - val_loss: 0.8537 - val_accuracy: 0.7902\n",
            "Epoch 45/300\n",
            "8190/8190 - 1s - loss: 0.0960 - accuracy: 0.9674 - val_loss: 1.0585 - val_accuracy: 0.7415\n",
            "Epoch 46/300\n",
            "8190/8190 - 1s - loss: 0.1069 - accuracy: 0.9630 - val_loss: 0.9469 - val_accuracy: 0.7341\n",
            "Epoch 47/300\n",
            "8190/8190 - 1s - loss: 0.0988 - accuracy: 0.9663 - val_loss: 1.0376 - val_accuracy: 0.7463\n",
            "Epoch 48/300\n",
            "8190/8190 - 1s - loss: 0.1046 - accuracy: 0.9654 - val_loss: 0.9796 - val_accuracy: 0.7463\n",
            "Epoch 49/300\n",
            "8190/8190 - 1s - loss: 0.0832 - accuracy: 0.9734 - val_loss: 0.8796 - val_accuracy: 0.7610\n",
            "Epoch 50/300\n",
            "8190/8190 - 1s - loss: 0.0957 - accuracy: 0.9659 - val_loss: 0.9687 - val_accuracy: 0.7659\n",
            "Epoch 51/300\n",
            "8190/8190 - 1s - loss: 0.0858 - accuracy: 0.9717 - val_loss: 0.9954 - val_accuracy: 0.7634\n",
            "Epoch 52/300\n",
            "8190/8190 - 1s - loss: 0.0975 - accuracy: 0.9686 - val_loss: 1.0119 - val_accuracy: 0.7512\n",
            "Epoch 53/300\n",
            "8190/8190 - 1s - loss: 0.0840 - accuracy: 0.9719 - val_loss: 0.9415 - val_accuracy: 0.7829\n",
            "Epoch 54/300\n",
            "8190/8190 - 1s - loss: 0.0931 - accuracy: 0.9705 - val_loss: 0.9196 - val_accuracy: 0.7683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.callbacks.History at 0x7f9fc09d0710>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fFajOqlNaTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c21721b-f621-434b-ffea-5134617accf8"
      },
      "source": [
        "model_train_ver2(train,4,aug_number = 3)"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_114 (Conv2D)          (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_117 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_59 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 489,354\n",
            "Trainable params: 489,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(2294, 28, 28, 1)\n",
            "(2294, 10)\n",
            "Train on 2294 samples, validate on 410 samples\n",
            "Epoch 1/300\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f9f73e7bc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f9f73e7bc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "2294/2294 - 1s - loss: 3.0969 - accuracy: 0.3156 - val_loss: 2.3044 - val_accuracy: 0.1000\n",
            "Epoch 2/300\n",
            "2294/2294 - 0s - loss: 2.0777 - accuracy: 0.3575 - val_loss: 2.3314 - val_accuracy: 0.1000\n",
            "Epoch 3/300\n",
            "2294/2294 - 0s - loss: 2.0367 - accuracy: 0.3575 - val_loss: 2.2914 - val_accuracy: 0.1000\n",
            "Epoch 4/300\n",
            "2294/2294 - 0s - loss: 1.9953 - accuracy: 0.3575 - val_loss: 2.2370 - val_accuracy: 0.1171\n",
            "Epoch 5/300\n",
            "2294/2294 - 0s - loss: 1.9447 - accuracy: 0.3601 - val_loss: 2.1867 - val_accuracy: 0.2049\n",
            "Epoch 6/300\n",
            "2294/2294 - 0s - loss: 1.8842 - accuracy: 0.3775 - val_loss: 2.0863 - val_accuracy: 0.2317\n",
            "Epoch 7/300\n",
            "2294/2294 - 0s - loss: 1.8332 - accuracy: 0.3932 - val_loss: 2.0309 - val_accuracy: 0.2512\n",
            "Epoch 8/300\n",
            "2294/2294 - 0s - loss: 1.7486 - accuracy: 0.4019 - val_loss: 1.8728 - val_accuracy: 0.3585\n",
            "Epoch 9/300\n",
            "2294/2294 - 0s - loss: 1.6346 - accuracy: 0.4503 - val_loss: 1.7678 - val_accuracy: 0.4098\n",
            "Epoch 10/300\n",
            "2294/2294 - 0s - loss: 1.5037 - accuracy: 0.4939 - val_loss: 1.7036 - val_accuracy: 0.4195\n",
            "Epoch 11/300\n",
            "2294/2294 - 0s - loss: 1.4103 - accuracy: 0.5248 - val_loss: 1.5398 - val_accuracy: 0.5073\n",
            "Epoch 12/300\n",
            "2294/2294 - 0s - loss: 1.2674 - accuracy: 0.5684 - val_loss: 1.3557 - val_accuracy: 0.5707\n",
            "Epoch 13/300\n",
            "2294/2294 - 0s - loss: 1.1661 - accuracy: 0.6090 - val_loss: 1.1882 - val_accuracy: 0.6317\n",
            "Epoch 14/300\n",
            "2294/2294 - 0s - loss: 1.0639 - accuracy: 0.6456 - val_loss: 1.1372 - val_accuracy: 0.6610\n",
            "Epoch 15/300\n",
            "2294/2294 - 0s - loss: 0.9778 - accuracy: 0.6901 - val_loss: 1.0751 - val_accuracy: 0.6537\n",
            "Epoch 16/300\n",
            "2294/2294 - 0s - loss: 0.9237 - accuracy: 0.6970 - val_loss: 1.0957 - val_accuracy: 0.6537\n",
            "Epoch 17/300\n",
            "2294/2294 - 0s - loss: 0.8765 - accuracy: 0.7101 - val_loss: 0.8575 - val_accuracy: 0.7122\n",
            "Epoch 18/300\n",
            "2294/2294 - 0s - loss: 0.8133 - accuracy: 0.7319 - val_loss: 0.8682 - val_accuracy: 0.7317\n",
            "Epoch 19/300\n",
            "2294/2294 - 0s - loss: 0.7312 - accuracy: 0.7515 - val_loss: 0.8787 - val_accuracy: 0.7220\n",
            "Epoch 20/300\n",
            "2294/2294 - 0s - loss: 0.7274 - accuracy: 0.7616 - val_loss: 0.8330 - val_accuracy: 0.7341\n",
            "Epoch 21/300\n",
            "2294/2294 - 0s - loss: 0.6656 - accuracy: 0.7816 - val_loss: 0.7253 - val_accuracy: 0.7707\n",
            "Epoch 22/300\n",
            "2294/2294 - 0s - loss: 0.5932 - accuracy: 0.8030 - val_loss: 0.6840 - val_accuracy: 0.7683\n",
            "Epoch 23/300\n",
            "2294/2294 - 0s - loss: 0.5391 - accuracy: 0.8248 - val_loss: 0.6291 - val_accuracy: 0.8098\n",
            "Epoch 24/300\n",
            "2294/2294 - 0s - loss: 0.5086 - accuracy: 0.8217 - val_loss: 0.6894 - val_accuracy: 0.7683\n",
            "Epoch 25/300\n",
            "2294/2294 - 0s - loss: 0.5109 - accuracy: 0.8248 - val_loss: 0.5854 - val_accuracy: 0.8220\n",
            "Epoch 26/300\n",
            "2294/2294 - 0s - loss: 0.4760 - accuracy: 0.8361 - val_loss: 0.7198 - val_accuracy: 0.7707\n",
            "Epoch 27/300\n",
            "2294/2294 - 0s - loss: 0.4424 - accuracy: 0.8466 - val_loss: 0.5537 - val_accuracy: 0.8317\n",
            "Epoch 28/300\n",
            "2294/2294 - 0s - loss: 0.3981 - accuracy: 0.8596 - val_loss: 0.5902 - val_accuracy: 0.8244\n",
            "Epoch 29/300\n",
            "2294/2294 - 0s - loss: 0.3750 - accuracy: 0.8714 - val_loss: 0.5640 - val_accuracy: 0.8390\n",
            "Epoch 30/300\n",
            "2294/2294 - 0s - loss: 0.3588 - accuracy: 0.8797 - val_loss: 0.6436 - val_accuracy: 0.8220\n",
            "Epoch 31/300\n",
            "2294/2294 - 0s - loss: 0.3581 - accuracy: 0.8793 - val_loss: 0.5687 - val_accuracy: 0.8195\n",
            "Epoch 32/300\n",
            "2294/2294 - 0s - loss: 0.3165 - accuracy: 0.8958 - val_loss: 0.5885 - val_accuracy: 0.8171\n",
            "Epoch 33/300\n",
            "2294/2294 - 0s - loss: 0.3180 - accuracy: 0.8954 - val_loss: 0.5540 - val_accuracy: 0.8220\n",
            "Epoch 34/300\n",
            "2294/2294 - 0s - loss: 0.2897 - accuracy: 0.9089 - val_loss: 0.4921 - val_accuracy: 0.8512\n",
            "Epoch 35/300\n",
            "2294/2294 - 0s - loss: 0.2860 - accuracy: 0.8997 - val_loss: 0.5440 - val_accuracy: 0.8317\n",
            "Epoch 36/300\n",
            "2294/2294 - 0s - loss: 0.2649 - accuracy: 0.9015 - val_loss: 0.5607 - val_accuracy: 0.8293\n",
            "Epoch 37/300\n",
            "2294/2294 - 0s - loss: 0.2439 - accuracy: 0.9159 - val_loss: 0.5726 - val_accuracy: 0.8512\n",
            "Epoch 38/300\n",
            "2294/2294 - 0s - loss: 0.2748 - accuracy: 0.9106 - val_loss: 0.4735 - val_accuracy: 0.8756\n",
            "Epoch 39/300\n",
            "2294/2294 - 0s - loss: 0.2226 - accuracy: 0.9246 - val_loss: 0.4949 - val_accuracy: 0.8585\n",
            "Epoch 40/300\n",
            "2294/2294 - 0s - loss: 0.2342 - accuracy: 0.9180 - val_loss: 0.5128 - val_accuracy: 0.8537\n",
            "Epoch 41/300\n",
            "2294/2294 - 0s - loss: 0.2061 - accuracy: 0.9268 - val_loss: 0.5192 - val_accuracy: 0.8610\n",
            "Epoch 42/300\n",
            "2294/2294 - 0s - loss: 0.2151 - accuracy: 0.9220 - val_loss: 0.5572 - val_accuracy: 0.8537\n",
            "Epoch 43/300\n",
            "2294/2294 - 0s - loss: 0.2080 - accuracy: 0.9294 - val_loss: 0.5124 - val_accuracy: 0.8244\n",
            "Epoch 44/300\n",
            "2294/2294 - 0s - loss: 0.2096 - accuracy: 0.9285 - val_loss: 0.5582 - val_accuracy: 0.8244\n",
            "Epoch 45/300\n",
            "2294/2294 - 0s - loss: 0.1867 - accuracy: 0.9377 - val_loss: 0.5034 - val_accuracy: 0.8634\n",
            "Epoch 46/300\n",
            "2294/2294 - 0s - loss: 0.1625 - accuracy: 0.9446 - val_loss: 0.4984 - val_accuracy: 0.8780\n",
            "Epoch 47/300\n",
            "2294/2294 - 0s - loss: 0.1802 - accuracy: 0.9372 - val_loss: 0.5721 - val_accuracy: 0.8512\n",
            "Epoch 48/300\n",
            "2294/2294 - 0s - loss: 0.1593 - accuracy: 0.9477 - val_loss: 0.5106 - val_accuracy: 0.8683\n",
            "Epoch 49/300\n",
            "2294/2294 - 0s - loss: 0.1509 - accuracy: 0.9446 - val_loss: 0.5569 - val_accuracy: 0.8512\n",
            "Epoch 50/300\n",
            "2294/2294 - 0s - loss: 0.1520 - accuracy: 0.9438 - val_loss: 0.5883 - val_accuracy: 0.8439\n",
            "Epoch 51/300\n",
            "2294/2294 - 0s - loss: 0.1529 - accuracy: 0.9464 - val_loss: 0.5448 - val_accuracy: 0.8683\n",
            "Epoch 52/300\n",
            "2294/2294 - 0s - loss: 0.1384 - accuracy: 0.9529 - val_loss: 0.4978 - val_accuracy: 0.8732\n",
            "Epoch 53/300\n",
            "2294/2294 - 0s - loss: 0.1345 - accuracy: 0.9507 - val_loss: 0.4873 - val_accuracy: 0.8878\n",
            "Epoch 54/300\n",
            "2294/2294 - 0s - loss: 0.1632 - accuracy: 0.9398 - val_loss: 0.5004 - val_accuracy: 0.8732\n",
            "Epoch 55/300\n",
            "2294/2294 - 0s - loss: 0.1349 - accuracy: 0.9503 - val_loss: 0.6032 - val_accuracy: 0.8659\n",
            "Epoch 56/300\n",
            "2294/2294 - 0s - loss: 0.1484 - accuracy: 0.9555 - val_loss: 0.5272 - val_accuracy: 0.8756\n",
            "Epoch 57/300\n",
            "2294/2294 - 0s - loss: 0.1339 - accuracy: 0.9534 - val_loss: 0.4933 - val_accuracy: 0.8854\n",
            "Epoch 58/300\n",
            "2294/2294 - 0s - loss: 0.1045 - accuracy: 0.9664 - val_loss: 0.5497 - val_accuracy: 0.8902\n",
            "Epoch 59/300\n",
            "2294/2294 - 0s - loss: 0.1204 - accuracy: 0.9573 - val_loss: 0.5264 - val_accuracy: 0.8634\n",
            "Epoch 60/300\n",
            "2294/2294 - 0s - loss: 0.1181 - accuracy: 0.9595 - val_loss: 0.5247 - val_accuracy: 0.8707\n",
            "Epoch 61/300\n",
            "2294/2294 - 0s - loss: 0.1200 - accuracy: 0.9555 - val_loss: 0.4938 - val_accuracy: 0.8780\n",
            "Epoch 62/300\n",
            "2294/2294 - 0s - loss: 0.1050 - accuracy: 0.9677 - val_loss: 0.5780 - val_accuracy: 0.8561\n",
            "Epoch 63/300\n",
            "2294/2294 - 0s - loss: 0.1103 - accuracy: 0.9595 - val_loss: 0.5460 - val_accuracy: 0.8683\n",
            "Epoch 64/300\n",
            "2294/2294 - 0s - loss: 0.1221 - accuracy: 0.9573 - val_loss: 0.4683 - val_accuracy: 0.8829\n",
            "Epoch 65/300\n",
            "2294/2294 - 0s - loss: 0.0998 - accuracy: 0.9643 - val_loss: 0.5026 - val_accuracy: 0.8780\n",
            "Epoch 66/300\n",
            "2294/2294 - 0s - loss: 0.0936 - accuracy: 0.9669 - val_loss: 0.5390 - val_accuracy: 0.8902\n",
            "Epoch 67/300\n",
            "2294/2294 - 0s - loss: 0.0804 - accuracy: 0.9730 - val_loss: 0.6077 - val_accuracy: 0.8659\n",
            "Epoch 68/300\n",
            "2294/2294 - 0s - loss: 0.0944 - accuracy: 0.9656 - val_loss: 0.6639 - val_accuracy: 0.8439\n",
            "Epoch 69/300\n",
            "2294/2294 - 0s - loss: 0.0940 - accuracy: 0.9656 - val_loss: 0.5116 - val_accuracy: 0.8878\n",
            "Epoch 70/300\n",
            "2294/2294 - 0s - loss: 0.0967 - accuracy: 0.9629 - val_loss: 0.6220 - val_accuracy: 0.8512\n",
            "Epoch 71/300\n",
            "2294/2294 - 0s - loss: 0.0865 - accuracy: 0.9712 - val_loss: 0.5609 - val_accuracy: 0.8488\n",
            "Epoch 72/300\n",
            "2294/2294 - 0s - loss: 0.1208 - accuracy: 0.9629 - val_loss: 0.6267 - val_accuracy: 0.8415\n",
            "Epoch 73/300\n",
            "2294/2294 - 0s - loss: 0.0822 - accuracy: 0.9743 - val_loss: 0.5744 - val_accuracy: 0.8707\n",
            "Epoch 74/300\n",
            "2294/2294 - 0s - loss: 0.0820 - accuracy: 0.9743 - val_loss: 0.6372 - val_accuracy: 0.8683\n",
            "Epoch 75/300\n",
            "2294/2294 - 0s - loss: 0.0887 - accuracy: 0.9695 - val_loss: 0.5731 - val_accuracy: 0.8683\n",
            "Epoch 76/300\n",
            "2294/2294 - 0s - loss: 0.0752 - accuracy: 0.9725 - val_loss: 0.5931 - val_accuracy: 0.8610\n",
            "Epoch 77/300\n",
            "2294/2294 - 0s - loss: 0.0889 - accuracy: 0.9695 - val_loss: 0.5397 - val_accuracy: 0.8805\n",
            "Epoch 78/300\n",
            "2294/2294 - 0s - loss: 0.0679 - accuracy: 0.9778 - val_loss: 0.5810 - val_accuracy: 0.8707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.callbacks.History at 0x7f9f73e91588>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwwCA-1iNaea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d88a5b7-30cb-4859-ddfa-1f1dda183301"
      },
      "source": [
        "model_train_ver2(train,3,aug_number = 8)"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_108 (Conv2D)          (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 489,354\n",
            "Trainable params: 489,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(2223, 28, 28, 1)\n",
            "(2223, 10)\n",
            "Train on 2223 samples, validate on 409 samples\n",
            "Epoch 1/300\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f9f74bd7f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f9f74bd7f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "2223/2223 - 2s - loss: 2.9534 - accuracy: 0.2753 - val_loss: 2.3149 - val_accuracy: 0.0880\n",
            "Epoch 2/300\n",
            "2223/2223 - 0s - loss: 2.0901 - accuracy: 0.3284 - val_loss: 2.3093 - val_accuracy: 0.0880\n",
            "Epoch 3/300\n",
            "2223/2223 - 0s - loss: 2.0876 - accuracy: 0.3284 - val_loss: 2.3244 - val_accuracy: 0.0880\n",
            "Epoch 4/300\n",
            "2223/2223 - 0s - loss: 2.0688 - accuracy: 0.3284 - val_loss: 2.3086 - val_accuracy: 0.0880\n",
            "Epoch 5/300\n",
            "2223/2223 - 0s - loss: 2.0632 - accuracy: 0.3284 - val_loss: 2.2965 - val_accuracy: 0.0880\n",
            "Epoch 6/300\n",
            "2223/2223 - 0s - loss: 2.0348 - accuracy: 0.3297 - val_loss: 2.2856 - val_accuracy: 0.0905\n",
            "Epoch 7/300\n",
            "2223/2223 - 0s - loss: 2.0313 - accuracy: 0.3320 - val_loss: 2.2908 - val_accuracy: 0.0954\n",
            "Epoch 8/300\n",
            "2223/2223 - 0s - loss: 1.9828 - accuracy: 0.3356 - val_loss: 2.1763 - val_accuracy: 0.1467\n",
            "Epoch 9/300\n",
            "2223/2223 - 0s - loss: 1.9436 - accuracy: 0.3378 - val_loss: 2.1137 - val_accuracy: 0.2347\n",
            "Epoch 10/300\n",
            "2223/2223 - 0s - loss: 1.8887 - accuracy: 0.3455 - val_loss: 2.0505 - val_accuracy: 0.2689\n",
            "Epoch 11/300\n",
            "2223/2223 - 0s - loss: 1.8321 - accuracy: 0.3738 - val_loss: 1.9650 - val_accuracy: 0.2812\n",
            "Epoch 12/300\n",
            "2223/2223 - 0s - loss: 1.7181 - accuracy: 0.4116 - val_loss: 1.8163 - val_accuracy: 0.4034\n",
            "Epoch 13/300\n",
            "2223/2223 - 0s - loss: 1.6240 - accuracy: 0.4512 - val_loss: 1.5846 - val_accuracy: 0.4963\n",
            "Epoch 14/300\n",
            "2223/2223 - 0s - loss: 1.4818 - accuracy: 0.4984 - val_loss: 1.4816 - val_accuracy: 0.4939\n",
            "Epoch 15/300\n",
            "2223/2223 - 0s - loss: 1.3272 - accuracy: 0.5533 - val_loss: 1.2238 - val_accuracy: 0.5990\n",
            "Epoch 16/300\n",
            "2223/2223 - 0s - loss: 1.2054 - accuracy: 0.5803 - val_loss: 1.1205 - val_accuracy: 0.6210\n",
            "Epoch 17/300\n",
            "2223/2223 - 0s - loss: 1.1235 - accuracy: 0.6239 - val_loss: 1.0761 - val_accuracy: 0.6528\n",
            "Epoch 18/300\n",
            "2223/2223 - 0s - loss: 1.0220 - accuracy: 0.6491 - val_loss: 0.9813 - val_accuracy: 0.6822\n",
            "Epoch 19/300\n",
            "2223/2223 - 0s - loss: 0.9463 - accuracy: 0.6905 - val_loss: 1.0807 - val_accuracy: 0.6235\n",
            "Epoch 20/300\n",
            "2223/2223 - 0s - loss: 0.9089 - accuracy: 0.6941 - val_loss: 0.8860 - val_accuracy: 0.6870\n",
            "Epoch 21/300\n",
            "2223/2223 - 0s - loss: 0.7994 - accuracy: 0.7202 - val_loss: 0.8596 - val_accuracy: 0.7066\n",
            "Epoch 22/300\n",
            "2223/2223 - 0s - loss: 0.7482 - accuracy: 0.7440 - val_loss: 0.7404 - val_accuracy: 0.7579\n",
            "Epoch 23/300\n",
            "2223/2223 - 0s - loss: 0.6866 - accuracy: 0.7562 - val_loss: 0.7631 - val_accuracy: 0.7628\n",
            "Epoch 24/300\n",
            "2223/2223 - 0s - loss: 0.6675 - accuracy: 0.7562 - val_loss: 0.7922 - val_accuracy: 0.7384\n",
            "Epoch 25/300\n",
            "2223/2223 - 0s - loss: 0.6604 - accuracy: 0.7773 - val_loss: 0.6768 - val_accuracy: 0.7946\n",
            "Epoch 26/300\n",
            "2223/2223 - 0s - loss: 0.5578 - accuracy: 0.8151 - val_loss: 0.6161 - val_accuracy: 0.8020\n",
            "Epoch 27/300\n",
            "2223/2223 - 0s - loss: 0.5225 - accuracy: 0.8232 - val_loss: 0.6693 - val_accuracy: 0.7800\n",
            "Epoch 28/300\n",
            "2223/2223 - 0s - loss: 0.4783 - accuracy: 0.8268 - val_loss: 0.6065 - val_accuracy: 0.8313\n",
            "Epoch 29/300\n",
            "2223/2223 - 0s - loss: 0.4682 - accuracy: 0.8322 - val_loss: 0.6613 - val_accuracy: 0.7848\n",
            "Epoch 30/300\n",
            "2223/2223 - 0s - loss: 0.4315 - accuracy: 0.8516 - val_loss: 0.5984 - val_accuracy: 0.8191\n",
            "Epoch 31/300\n",
            "2223/2223 - 0s - loss: 0.4229 - accuracy: 0.8601 - val_loss: 0.5528 - val_accuracy: 0.8215\n",
            "Epoch 32/300\n",
            "2223/2223 - 0s - loss: 0.3889 - accuracy: 0.8686 - val_loss: 0.5724 - val_accuracy: 0.8240\n",
            "Epoch 33/300\n",
            "2223/2223 - 0s - loss: 0.3888 - accuracy: 0.8709 - val_loss: 0.6080 - val_accuracy: 0.8093\n",
            "Epoch 34/300\n",
            "2223/2223 - 0s - loss: 0.3670 - accuracy: 0.8772 - val_loss: 0.5593 - val_accuracy: 0.8264\n",
            "Epoch 35/300\n",
            "2223/2223 - 0s - loss: 0.3300 - accuracy: 0.8817 - val_loss: 0.4954 - val_accuracy: 0.8435\n",
            "Epoch 36/300\n",
            "2223/2223 - 0s - loss: 0.3209 - accuracy: 0.8844 - val_loss: 0.5781 - val_accuracy: 0.8313\n",
            "Epoch 37/300\n",
            "2223/2223 - 0s - loss: 0.3120 - accuracy: 0.8934 - val_loss: 0.5678 - val_accuracy: 0.8215\n",
            "Epoch 38/300\n",
            "2223/2223 - 0s - loss: 0.2809 - accuracy: 0.9019 - val_loss: 0.6522 - val_accuracy: 0.8362\n",
            "Epoch 39/300\n",
            "2223/2223 - 0s - loss: 0.2958 - accuracy: 0.9042 - val_loss: 0.5995 - val_accuracy: 0.8142\n",
            "Epoch 40/300\n",
            "2223/2223 - 0s - loss: 0.2351 - accuracy: 0.9181 - val_loss: 0.6461 - val_accuracy: 0.8215\n",
            "Epoch 41/300\n",
            "2223/2223 - 0s - loss: 0.2612 - accuracy: 0.9060 - val_loss: 0.5716 - val_accuracy: 0.8289\n",
            "Epoch 42/300\n",
            "2223/2223 - 0s - loss: 0.2180 - accuracy: 0.9199 - val_loss: 0.7312 - val_accuracy: 0.8289\n",
            "Epoch 43/300\n",
            "2223/2223 - 0s - loss: 0.2104 - accuracy: 0.9226 - val_loss: 0.5628 - val_accuracy: 0.8362\n",
            "Epoch 44/300\n",
            "2223/2223 - 0s - loss: 0.2082 - accuracy: 0.9280 - val_loss: 0.5829 - val_accuracy: 0.8215\n",
            "Epoch 45/300\n",
            "2223/2223 - 0s - loss: 0.2003 - accuracy: 0.9276 - val_loss: 0.7097 - val_accuracy: 0.8264\n",
            "Epoch 46/300\n",
            "2223/2223 - 0s - loss: 0.2250 - accuracy: 0.9217 - val_loss: 0.5975 - val_accuracy: 0.8191\n",
            "Epoch 47/300\n",
            "2223/2223 - 0s - loss: 0.2100 - accuracy: 0.9267 - val_loss: 0.5789 - val_accuracy: 0.8386\n",
            "Epoch 48/300\n",
            "2223/2223 - 0s - loss: 0.1889 - accuracy: 0.9388 - val_loss: 0.5707 - val_accuracy: 0.8215\n",
            "Epoch 49/300\n",
            "2223/2223 - 0s - loss: 0.1612 - accuracy: 0.9442 - val_loss: 0.5955 - val_accuracy: 0.8215\n",
            "Epoch 50/300\n",
            "2223/2223 - 0s - loss: 0.1576 - accuracy: 0.9429 - val_loss: 0.6177 - val_accuracy: 0.8362\n",
            "Epoch 51/300\n",
            "2223/2223 - 1s - loss: 0.1498 - accuracy: 0.9492 - val_loss: 0.5256 - val_accuracy: 0.8484\n",
            "Epoch 52/300\n",
            "2223/2223 - 0s - loss: 0.1704 - accuracy: 0.9361 - val_loss: 0.6277 - val_accuracy: 0.8191\n",
            "Epoch 53/300\n",
            "2223/2223 - 0s - loss: 0.1524 - accuracy: 0.9487 - val_loss: 0.6164 - val_accuracy: 0.8289\n",
            "Epoch 54/300\n",
            "2223/2223 - 0s - loss: 0.1626 - accuracy: 0.9469 - val_loss: 0.6426 - val_accuracy: 0.8313\n",
            "Epoch 55/300\n",
            "2223/2223 - 0s - loss: 0.1737 - accuracy: 0.9379 - val_loss: 0.6006 - val_accuracy: 0.8337\n",
            "Epoch 56/300\n",
            "2223/2223 - 0s - loss: 0.1709 - accuracy: 0.9429 - val_loss: 0.5533 - val_accuracy: 0.8337\n",
            "Epoch 57/300\n",
            "2223/2223 - 0s - loss: 0.1372 - accuracy: 0.9523 - val_loss: 0.5384 - val_accuracy: 0.8484\n",
            "Epoch 58/300\n",
            "2223/2223 - 0s - loss: 0.1530 - accuracy: 0.9550 - val_loss: 0.6020 - val_accuracy: 0.8411\n",
            "Epoch 59/300\n",
            "2223/2223 - 0s - loss: 0.1475 - accuracy: 0.9456 - val_loss: 0.5664 - val_accuracy: 0.8386\n",
            "Epoch 60/300\n",
            "2223/2223 - 0s - loss: 0.1441 - accuracy: 0.9528 - val_loss: 0.6051 - val_accuracy: 0.8411\n",
            "Epoch 61/300\n",
            "2223/2223 - 0s - loss: 0.1129 - accuracy: 0.9645 - val_loss: 0.6680 - val_accuracy: 0.8386\n",
            "Epoch 62/300\n",
            "2223/2223 - 0s - loss: 0.1215 - accuracy: 0.9591 - val_loss: 0.5687 - val_accuracy: 0.8509\n",
            "Epoch 63/300\n",
            "2223/2223 - 0s - loss: 0.1083 - accuracy: 0.9618 - val_loss: 0.5994 - val_accuracy: 0.8484\n",
            "Epoch 64/300\n",
            "2223/2223 - 0s - loss: 0.1316 - accuracy: 0.9564 - val_loss: 0.5332 - val_accuracy: 0.8460\n",
            "Epoch 65/300\n",
            "2223/2223 - 0s - loss: 0.1052 - accuracy: 0.9595 - val_loss: 0.5728 - val_accuracy: 0.8557\n",
            "Epoch 66/300\n",
            "2223/2223 - 0s - loss: 0.1206 - accuracy: 0.9595 - val_loss: 0.5842 - val_accuracy: 0.8509\n",
            "Epoch 67/300\n",
            "2223/2223 - 0s - loss: 0.1256 - accuracy: 0.9537 - val_loss: 0.6823 - val_accuracy: 0.8337\n",
            "Epoch 68/300\n",
            "2223/2223 - 0s - loss: 0.1142 - accuracy: 0.9595 - val_loss: 0.5263 - val_accuracy: 0.8631\n",
            "Epoch 69/300\n",
            "2223/2223 - 0s - loss: 0.1168 - accuracy: 0.9613 - val_loss: 0.5708 - val_accuracy: 0.8557\n",
            "Epoch 70/300\n",
            "2223/2223 - 0s - loss: 0.1106 - accuracy: 0.9640 - val_loss: 0.7196 - val_accuracy: 0.8386\n",
            "Epoch 71/300\n",
            "2223/2223 - 0s - loss: 0.1059 - accuracy: 0.9604 - val_loss: 0.5835 - val_accuracy: 0.8411\n",
            "Epoch 72/300\n",
            "2223/2223 - 0s - loss: 0.0883 - accuracy: 0.9667 - val_loss: 0.6995 - val_accuracy: 0.8557\n",
            "Epoch 73/300\n",
            "2223/2223 - 0s - loss: 0.0959 - accuracy: 0.9649 - val_loss: 0.7615 - val_accuracy: 0.8460\n",
            "Epoch 74/300\n",
            "2223/2223 - 0s - loss: 0.1148 - accuracy: 0.9564 - val_loss: 0.6401 - val_accuracy: 0.8509\n",
            "Epoch 75/300\n",
            "2223/2223 - 0s - loss: 0.1011 - accuracy: 0.9631 - val_loss: 0.6630 - val_accuracy: 0.8289\n",
            "Epoch 76/300\n",
            "2223/2223 - 0s - loss: 0.0795 - accuracy: 0.9739 - val_loss: 0.8610 - val_accuracy: 0.8264\n",
            "Epoch 77/300\n",
            "2223/2223 - 0s - loss: 0.0882 - accuracy: 0.9717 - val_loss: 0.6982 - val_accuracy: 0.8264\n",
            "Epoch 78/300\n",
            "2223/2223 - 0s - loss: 0.0768 - accuracy: 0.9748 - val_loss: 0.7395 - val_accuracy: 0.8411\n",
            "Epoch 79/300\n",
            "2223/2223 - 0s - loss: 0.0911 - accuracy: 0.9694 - val_loss: 0.6519 - val_accuracy: 0.8460\n",
            "Epoch 80/300\n",
            "2223/2223 - 0s - loss: 0.0827 - accuracy: 0.9721 - val_loss: 0.7679 - val_accuracy: 0.8313\n",
            "Epoch 81/300\n",
            "2223/2223 - 0s - loss: 0.1040 - accuracy: 0.9667 - val_loss: 0.6105 - val_accuracy: 0.8582\n",
            "Epoch 82/300\n",
            "2223/2223 - 0s - loss: 0.1293 - accuracy: 0.9604 - val_loss: 0.6781 - val_accuracy: 0.8411\n",
            "Epoch 83/300\n",
            "2223/2223 - 0s - loss: 0.0838 - accuracy: 0.9712 - val_loss: 0.6278 - val_accuracy: 0.8631\n",
            "Epoch 84/300\n",
            "2223/2223 - 0s - loss: 0.0856 - accuracy: 0.9694 - val_loss: 0.6846 - val_accuracy: 0.8411\n",
            "Epoch 85/300\n",
            "2223/2223 - 0s - loss: 0.0665 - accuracy: 0.9757 - val_loss: 0.7861 - val_accuracy: 0.8337\n",
            "Epoch 86/300\n",
            "2223/2223 - 0s - loss: 0.0643 - accuracy: 0.9757 - val_loss: 0.7309 - val_accuracy: 0.8484\n",
            "Epoch 87/300\n",
            "2223/2223 - 0s - loss: 0.0585 - accuracy: 0.9802 - val_loss: 0.8218 - val_accuracy: 0.8460\n",
            "Epoch 88/300\n",
            "2223/2223 - 0s - loss: 0.0520 - accuracy: 0.9807 - val_loss: 0.7488 - val_accuracy: 0.8386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.callbacks.History at 0x7f9f74b88b00>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3SycUT0NaG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNv01Wyz0mwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0qz5gmhPztj",
        "colab_type": "text"
      },
      "source": [
        "### CNN 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfSd1SLZUPEy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "outputId": "45f2738e-b826-4ebd-eddf-ffdcb1b7e84f"
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.6.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2xw495IescF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9d06fb77-6040-45a3-8d12-144eba4ff302"
      },
      "source": [
        "%tensorflow_version 2.3\n",
        "import tensorflow as tf"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.3`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBFmmHzEPztk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPr5xjT7Pztn",
        "colab_type": "text"
      },
      "source": [
        "#### CNN에 들어갈 수 있도록 np.array를 통해 데이터의 차원 변경 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_EC7B27Pzto",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "9a6d3e24-1ae3-4eb3-faf1-78885dc040b7"
      },
      "source": [
        "x_train=np.array(train.iloc[:,3:]).reshape(-1,28,28,1).astype(np.float)\n",
        "y_train=to_categorical(train['digit'].values)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-17e4937da20b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'digit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1603584 into shape (28,28,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRYgwUPMPzts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "9c2c7e2a-6f20-4799-8673-7e219bd40ce6"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-2132a220a582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E56lNV1Pztv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "408ef7e2-d3ff-4566-f088-b395b75bdbb9"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-30602697b5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEVn_Iy3Pzt0",
        "colab_type": "text"
      },
      "source": [
        "#### train data 와 validation data 를 나누어 모델의 학습에 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcxsQHT4Pzt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train , val 나누기 (0.2사용)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aqoFYTJPzt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJlSrheoPzt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-kL87YwPzuC",
        "colab_type": "text"
      },
      "source": [
        "#### 현재 데이터의 수가 적으므로 imagegenerator를 통해 데이터를 증식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJUjEZUcPzuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "661df849-bfe8-4007-8d70-5b8ef556f10d"
      },
      "source": [
        "#이미지 데이터 증식 여러각도로 바꾸어 본다. \n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest'\n",
        "    )\n",
        "train_datagen.fit(x_train)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-89aaea9f5bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfill_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest_datagen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixgrACwGPzuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "fad4f73e-4f95-459a-c6c0-7325301d669b"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2132a220a582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krwh6kuwPzuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRBrWKApPzuO",
        "colab_type": "text"
      },
      "source": [
        "#### 모델의 구성 (keras를 이용)\n",
        "1) Conv2D 계층과 그 뒤에 Pooling 계층을 연결\n",
        " - 초기에는 뒤의 Dense를 2개 두었지만 AlexNet을 모방하여 Dense를 늘리니 정확도가 상승\n",
        " \n",
        "2) 활성화 함수, 옵티마이저의 변경: Leaky Relu 와 nadam,adagrad,msd 등을 사용해 보았지만 adam이 정확도가 좋아보임\n",
        "\n",
        "3) Drop out 계층의 추가를 통해 정확도 상승 실험(Drop out 비율조정시 0.5가 좋아보임)\n",
        "\n",
        "4) padding을 적용시켜 데이터의 손실을 막아봄"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6AhrNQnPzuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_cnn():\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, kernel_size=3, activation='relu',padding='same',\n",
        "                          input_shape=x_train.shape[1:]))\n",
        "  model.add(layers.Conv2D(64, kernel_size=3,padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2,2)))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "\n",
        "  model.add(layers.Conv2D(64, kernel_size=3,padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(64, kernel_size=3,padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2,2)))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "\n",
        "  model.add(layers.Conv2D(128, kernel_size=3,padding='same', activation='relu'))\n",
        "  model.add(layers.Conv2D(128, kernel_size=3,padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2,2)))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(y_train.shape[1], activation='softmax'))\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdQy-0wyc0t9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utaBZVbzPzuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRUHzddAPzuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch=32\n",
        "epoch=300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA-kopFwPzud",
        "colab_type": "text"
      },
      "source": [
        "#### 모델의 학습과 Overfitting 방지 \n",
        "- Early stopping과 callback을 통해, 지속적으로 Val_accuracy를 모니터링 하여\\\n",
        "  학습이 진행되어가며 Val_accuracy가 개선되지 않으면(증가되거나 지속) 학습을 종료하고\\\n",
        "  가장 좋은 Val_accuray를 보여주었던 모델의 가중치를 best_model.h5로 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJRcTkpUnivb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.digit.value_counts() / train.digit.value_counts().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z4zfkcJnAaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weight = {\n",
        "    0: 0.093262,\n",
        "    1: 0.098633,\n",
        "    2: 0.113770,\n",
        "    3: 0.100098,\n",
        "    4: 0.101074,\n",
        "    5: 0.109863,\n",
        "    6: 0.103516,\n",
        "    7: 0.094727,\n",
        "    8: 0.088867,\n",
        "    9: 0.096191,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bErCxG-hPzue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50),\n",
        "            keras.callbacks.ModelCheckpoint(filepath='C:/workspace/DACON/EMNIST/model/best_model1.h5',monitor='val_accuracy',save_best_only=True)]\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch=x_train.shape[0]//batch, # 전체 데이터 수 / 배치 사이즈\n",
        "    epochs=epoch,\n",
        "    validation_data=test_datagen.flow(x_val, y_val),\n",
        "   # class_weight = class_weight,\n",
        "    verbose=2,\n",
        "    callbacks=early_stop\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLIg272APzui",
        "colab_type": "text"
      },
      "source": [
        "#### 모델의 학습과정과 val_accuray의 변화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2ZpIPm9jPzui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'bo', label='Validation acc')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtfzgsjPPzum",
        "colab_type": "text"
      },
      "source": [
        "### test데이터를 통한 모델의 정확도 검증\n",
        " 초기(08.01) : 0.72 (72%) 로 시작\\\n",
        " 마지막(08.15) : 0.86 (86%) 까지 증가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alb4KnbiPzun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test= pd.read_csv(io.BytesIO(uploaded['test.csv']))"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIy7U2n2Pzuq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "06434f58-14be-4d8b-ff8a-5ec3706bad27"
      },
      "source": [
        "bestmodel_1 = keras.models.load_model('/content/gdrive/My Drive/best_model_1.h5')\n",
        "bestmodel_2 = keras.models.load_model('/content/gdrive/My Drive/best_model_2.h5')\n",
        "bestmodel_3 = keras.models.load_model('/content/gdrive/My Drive/best_model_3.h5')\n",
        "bestmodel_4 = keras.models.load_model('/content/gdrive/My Drive/best_model_4.h5')"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L00uGO1qPzux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fd76f2d-adbf-4a26-e98b-e5572a5cae42"
      },
      "source": [
        "x_test = np.array(test.iloc[:, 2:]).reshape(-1, 28, 28, 1).astype(np.float)\n",
        "x_test /= 255.\n",
        "print(x_test.shape)\n"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20480, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYV2mO1p1gFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_1 = bestmodel_1.predict(x_test)\n",
        "pred_2 = bestmodel_1.predict(x_test)\n",
        "pred_3 = bestmodel_1.predict(x_test)\n",
        "pred_4 = bestmodel_1.predict(x_test)\n"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCWnfRXN1sSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred= (pred_1 + pred_2 +pred_3 + pred_4)/4"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_-r4PcJ1maP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4000b4f9-a549-4d31-b8e9-6e2762f4bfc3"
      },
      "source": [
        "\n",
        "pred = np.argmax(pred, axis=1)\n",
        "print(pred.shape)"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20480,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHtgC3__Pzu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "024f5c06-c35a-4f64-decb-1d905695425a"
      },
      "source": [
        "pred"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgBGoVQLPzu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission=pd.read_csv(\"C:\\\\Users\\\\Chunghun\\\\Desktop\\\\data\\\\submission.csv\",index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z0BzRb7Pzu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.digit = pred\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-pFutsuPzu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv(\"C:\\\\Users\\\\Chunghun\\\\Desktop\\\\data\\\\submission1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_iEafoRPzvC",
        "colab_type": "text"
      },
      "source": [
        "#### 이전 좋은 정확도를 보여줬던 모델들의 형태 기록 및 갱신\n",
        "- 앙상블을 통한 Voting 이 좋은 정확도를 보여줬었음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IHgfdcoiPzvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4faee70a-104d-4ef7-e5d7-b190f156af53"
      },
      "source": [
        "'''\n",
        "#best model5 = adam #val_accuracy = 0.8098 # batch size=32\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=3,padding='same', activation='relu',\n",
        "                        input_shape=x_train.shape[1:]))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, kernel_size=3,padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, kernel_size=3,padding='valid', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(y_train.shape[1], activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "#best model1= adam \n",
        "Epoch 90/300\n",
        "51/51 - 2s - loss: 0.4684 - accuracy: 0.8275 - val_loss: 0.4848 - val_accuracy: 0.8683\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=3,padding='same', activation='relu',\n",
        "                        input_shape=x_train.shape[1:]))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, kernel_size=3,padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, kernel_size=3,padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(y_train.shape[1], activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "'''\n",
        "\n"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n#best model5 = adam #val_accuracy = 0.8098 # batch size=32\\nmodel = keras.Sequential()\\nmodel.add(layers.Conv2D(32, kernel_size=3,padding='same', activation='relu',\\n                        input_shape=x_train.shape[1:]))\\nmodel.add(layers.MaxPooling2D((2,2)))\\nmodel.add(layers.Conv2D(64, kernel_size=3,padding='same', activation='relu'))\\nmodel.add(layers.MaxPooling2D((2,2)))\\nmodel.add(layers.Conv2D(128, kernel_size=3,padding='valid', activation='relu'))\\nmodel.add(layers.MaxPooling2D((2,2)))\\nmodel.add(layers.Dropout(0.1))\\nmodel.add(layers.Flatten())\\nmodel.add(layers.Dense(512, activation='relu'))\\nmodel.add(layers.Dense(256, activation='relu'))\\nmodel.add(layers.Dense(128, activation='relu'))\\nmodel.add(layers.Dense(y_train.shape[1], activation='softmax'))\\nmodel.summary()\\n\\n#best model1= adam \\nEpoch 90/300\\n51/51 - 2s - loss: 0.4684 - accuracy: 0.8275 - val_loss: 0.4848 - val_accuracy: 0.8683\\nmodel = keras.Sequential()\\nmodel.add(layers.Conv2D(32, kernel_size=3,padding='same', activation='relu',\\n                        input_shape=x_train.shape[1:]))\\nmodel.add(layers.MaxPooling2D((2,2)))\\nmodel.add(layers.Conv2D(64, kernel_size=3,padding='same', activation='relu'))\\nmodel.add(layers.MaxPooling2D((2,2)))\\nmodel.add(layers.Conv2D(128, kernel_size=3,padding='same', activation='relu'))\\nmodel.add(layers.MaxPooling2D((2,2)))\\nmodel.add(layers.Dropout(0.5))\\nmodel.add(layers.Flatten())\\nmodel.add(layers.Dense(512, activation='relu'))\\nmodel.add(layers.Dense(256, activation='relu'))\\nmodel.add(layers.Dense(128, activation='relu'))\\nmodel.add(layers.Dense(y_train.shape[1], activation='softmax'))\\nmodel.summary()\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0q7MbDiPzvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 286,
      "outputs": []
    }
  ]
}